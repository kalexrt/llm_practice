{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "Z43AcQ0lN1VE",
      "metadata": {
        "id": "Z43AcQ0lN1VE"
      },
      "source": [
        "# Importing Libraries and set up the api key"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "7e1837bc-b96c-4dea-9ba4-8a94afd05072",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7e1837bc-b96c-4dea-9ba4-8a94afd05072",
        "outputId": "1dfe903f-6a8c-47fc-8aa4-e495fd4279dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.43.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.5.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.8.2)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.10/dist-packages (from openai) (4.12.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.8)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.7.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.20.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai\n",
        "from openai import OpenAI\n",
        "from google.colab import userdata\n",
        "import json\n",
        "from nltk.translate import bleu_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "id": "ce17dbbc-3a31-48d4-8bd9-d7fe35e42c0b",
      "metadata": {
        "id": "ce17dbbc-3a31-48d4-8bd9-d7fe35e42c0b"
      },
      "outputs": [],
      "source": [
        "client = OpenAI(\n",
        "    api_key=userdata.get('API_KEY'),\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92rNKWiuOA_7",
      "metadata": {
        "id": "92rNKWiuOA_7"
      },
      "source": [
        "# Define the function to get responses from openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "415bedf3-127a-45cd-8108-4b26c61630f0",
      "metadata": {
        "id": "415bedf3-127a-45cd-8108-4b26c61630f0"
      },
      "outputs": [],
      "source": [
        "def get_completion(system_prompt, prompt, model=\"gpt-3.5-turbo\"):\n",
        "    messages = [\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\"role\": \"user\", \"content\": prompt}]\n",
        "    response = client.chat.completions.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=0,\n",
        "    )\n",
        "    return response.choices[0].message.content"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "p7HrHql1Oj1p",
      "metadata": {
        "id": "p7HrHql1Oj1p"
      },
      "source": [
        "# Test Datasets for all tasks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "21548a18-06bc-4538-a477-167be6485011",
      "metadata": {
        "id": "21548a18-06bc-4538-a477-167be6485011"
      },
      "outputs": [],
      "source": [
        "text_classification_data = [\n",
        "    (\"The capital of France is Paris.\", \"Factual\"),\n",
        "    (\"I believe chocolate is the best dessert.\", \"Opinion\"),\n",
        "    (\"It might rain tomorrow.\", \"Ambiguous\"),\n",
        "    (\"Mount Everest is the highest mountain in the world.\", \"Factual\"),\n",
        "    (\"In my opinion, summer is the best season.\", \"Opinion\"),\n",
        "    (\"She may arrive at the party tonight.\", \"Ambiguous\"),\n",
        "    (\"Pizza is delicious.\", \"Opinion\"),\n",
        "    (\"The Earth orbits around the Sun.\", \"Factual\"),\n",
        "    (\"Sunsets are beautiful.\", \"Opinion\"),\n",
        "    (\"Water boils at 100 degrees Celsius.\", \"Factual\"),\n",
        "    (\"Classical music is soothing.\", \"Opinion\"),\n",
        "    (\"The meeting could be postponed.\", \"Ambiguous\"),\n",
        "    (\"Football is the most popular sport globally.\", \"Opinion\"),\n",
        "    (\"She could decide to travel abroad.\", \"Ambiguous\"),\n",
        "    (\"Ice cream is better than cake.\", \"Opinion\")\n",
        "]\n",
        "logical_reasoning_data =[\n",
        "    (\"If it rains, the streets will be wet. It is raining.\", \"The streets are wet.\"),\n",
        "    (\"All squares are rectangles. This shape is a square.\", \"This shape is a rectangle.\"),\n",
        "    (\"If it is sunny, she will go for a walk. It is sunny.\", \"She will go for a walk.\"),\n",
        "    (\"All students must pass the final exam. John is a student.\", \"John must pass the final exam.\"),\n",
        "    (\"If the oven is turned on, the food will cook. The oven is turned on.\", \"The food is cooking.\"),\n",
        "    (\"All prime numbers are odd. Seven is a prime number.\", \"Seven is odd.\"),\n",
        "    (\"If he studies hard, he will pass the test. He studied hard.\", \"He will pass the test.\"),\n",
        "    (\"All mammals have hair. Whales are mammals.\", \"Whales have hair.\"),\n",
        "    (\"If it is cold outside, she wears a jacket. It is cold outside.\", \"She wears a jacket.\"),\n",
        "    (\"All metals conduct electricity. Copper is a metal.\", \"Copper conducts electricity.\")\n",
        "]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "X_4xutiEO13b",
      "metadata": {
        "id": "X_4xutiEO13b"
      },
      "source": [
        "# System Prompts for Tasks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "d9b3d7e8-dd4a-421e-94a1-77e627c2d83c",
      "metadata": {
        "id": "d9b3d7e8-dd4a-421e-94a1-77e627c2d83c"
      },
      "outputs": [],
      "source": [
        "text_classification_sys_prompt='''\n",
        "Classify given statements into one of three categories: factual,\n",
        "opinion, or ambiguous. Note that 'factual' does not necessarily mean 'true.' Display the output\n",
        "for each test case in JSON format.\n",
        "i have provided few examples delimited by <examples></examples>\n",
        "<examples>\n",
        "\n",
        "<example1>\n",
        "Input: The Earth is the third planet from the Sun.\n",
        "Expected Output:\n",
        "{\n",
        "\"text\": \"The Earth is the third planet from the Sun.\",\n",
        "\"label\": \"Factual\"\n",
        "}\n",
        "</example1>\n",
        "\n",
        "<example2>\n",
        "Input: Swmming is fun.\n",
        "Expected Output:\n",
        "{\n",
        "\"text\": \"Swmming is fun.\",\n",
        "\"label\": \"Opinion\"\n",
        "}\n",
        "</example2>\n",
        "\n",
        "<example3>\n",
        "Input: It might rain tomorrow.\n",
        "Expected Output:\n",
        "{\n",
        "\"text\": \"It might rain tomorrow.\",\n",
        "\"label\": \"Ambiguous\n",
        "}\n",
        "</example3>\n",
        "</examples>\n",
        "'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "id": "2a6619e5-8e4f-4b95-bb48-4ca0a823265f",
      "metadata": {
        "id": "2a6619e5-8e4f-4b95-bb48-4ca0a823265f"
      },
      "outputs": [],
      "source": [
        "logical_reasoning_sys_prompt='''\n",
        "Identify the conclusion from the given premises. Display the\n",
        "output in JSON format for all the test cases.\n",
        "Examples:\n",
        "Input:All birds have wings. A sparrow is a bird.\n",
        "Expected Output:\n",
        "{\n",
        "\"premises\": \"All birds have wings. A sparrow is a bird.\",\n",
        "\"conclusion\": \"A sparrow has wings\"\n",
        "}\n",
        "\n",
        "Input:If it snows, the ground will be covered in snow. It is\n",
        "snowing.\n",
        "Expected Output:\n",
        "{\n",
        "\"premises\": \"If it snows, the ground will be covered in snow. It is\n",
        "snowing.\",\n",
        "\"conclusion\": \"The ground is covered in snow\"\n",
        "}\n",
        "\n",
        "Input:All dogs are mammals. Max is a dog.\n",
        "Expected Output:\n",
        "{\n",
        "\"premises\": \"All dogs are mammals. Max is a dog.\",\n",
        "\"conclusion\": \"Max is a mammal\"\n",
        "}\n",
        "'''"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "g8ALtpEbO8RV",
      "metadata": {
        "id": "g8ALtpEbO8RV"
      },
      "source": [
        "# Task 1(Text Classification):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "63689da0-fd22-4143-8043-99d02c0d41aa",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "63689da0-fd22-4143-8043-99d02c0d41aa",
        "outputId": "8c665d05-c8bc-43bb-f5c4-15cd375f39f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "\"text\": \"The capital of France is Paris.\",\n",
            "\"label\": \"Factual\"\n",
            "}\n",
            "-------------------------------------------------------------------------\n",
            "{\n",
            "\"text\": \"I believe chocolate is the best dessert.\",\n",
            "\"label\": \"Opinion\"\n",
            "}\n",
            "-------------------------------------------------------------------------\n",
            "{\n",
            "\"text\": \"It might rain tomorrow.\",\n",
            "\"label\": \"Ambiguous\"\n",
            "}\n",
            "-------------------------------------------------------------------------\n",
            "{\n",
            "\"text\": \"Mount Everest is the highest mountain in the world.\",\n",
            "\"label\": \"Factual\"\n",
            "}\n",
            "-------------------------------------------------------------------------\n",
            "{\n",
            "\"text\": \"In my opinion, summer is the best season.\",\n",
            "\"label\": \"Opinion\"\n",
            "}\n",
            "-------------------------------------------------------------------------\n",
            "{\n",
            "\"text\": \"She may arrive at the party tonight.\",\n",
            "\"label\": \"Ambiguous\"\n",
            "}\n",
            "-------------------------------------------------------------------------\n",
            "{\n",
            "\"text\": \"Pizza is delicious.\",\n",
            "\"label\": \"Opinion\"\n",
            "}\n",
            "-------------------------------------------------------------------------\n",
            "{\n",
            "\"text\": \"The Earth orbits around the Sun.\",\n",
            "\"label\": \"Factual\"\n",
            "}\n",
            "-------------------------------------------------------------------------\n",
            "{\n",
            "\"text\": \"Sunsets are beautiful.\",\n",
            "\"label\": \"Opinion\"\n",
            "}\n",
            "-------------------------------------------------------------------------\n",
            "{\n",
            "\"text\": \"Water boils at 100 degrees Celsius.\",\n",
            "\"label\": \"Factual\"\n",
            "}\n",
            "-------------------------------------------------------------------------\n",
            "{\n",
            "\"text\": \"Classical music is soothing.\",\n",
            "\"label\": \"Opinion\"\n",
            "}\n",
            "-------------------------------------------------------------------------\n",
            "{\n",
            "\"text\": \"The meeting could be postponed.\",\n",
            "\"label\": \"Ambiguous\"\n",
            "}\n",
            "-------------------------------------------------------------------------\n",
            "{\n",
            "\"text\": \"Football is the most popular sport globally.\",\n",
            "\"label\": \"Factual\"\n",
            "}\n",
            "-------------------------------------------------------------------------\n",
            "{\n",
            "\"text\": \"She could decide to travel abroad.\",\n",
            "\"label\": \"Ambiguous\"\n",
            "}\n",
            "-------------------------------------------------------------------------\n",
            "{\n",
            "\"text\": \"Ice cream is better than cake.\",\n",
            "\"label\": \"Opinion\"\n",
            "}\n",
            "-------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "text_classification_responses = []\n",
        "for text in text_classification_data:\n",
        "  response = get_completion(text_classification_sys_prompt, text[0])\n",
        "  print(response)\n",
        "  print('-------------------------------------------------------------------------')\n",
        "  text_classification_responses.append(json.loads(response))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86LJNAjhPVQN",
      "metadata": {
        "id": "86LJNAjhPVQN"
      },
      "source": [
        "# Task 2(Text Classification Evaluation):"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "8njlI5SZxEc4",
      "metadata": {
        "id": "8njlI5SZxEc4"
      },
      "outputs": [],
      "source": [
        "def get_text_classification_evaluation():\n",
        "  correct = incorrect = 0\n",
        "  for i in range(len(text_classification_responses)):\n",
        "    if text_classification_responses[i]['label'] == text_classification_data[i][1]:\n",
        "      correct += 1\n",
        "    else:\n",
        "      incorrect += 1\n",
        "\n",
        "  total_num_text = correct + incorrect\n",
        "  accuracy = correct / total_num_text\n",
        "  results = {\n",
        "      \"Total_num_text\": total_num_text,\n",
        "      \"Total_correct_predictions\": correct,\n",
        "      \"Total_incorrect_predictions\": incorrect,\n",
        "      \"overall_accuracy\": accuracy\n",
        "  }\n",
        "  return results"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "id": "VtcdZ7Y82tkJ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VtcdZ7Y82tkJ",
        "outputId": "c5ef16ed-fc42-4ac7-fa9d-71c14bf4fcc6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'Total_num_text': 15, 'Total_correct_predictions': 14, 'Total_incorrect_predictions': 1, 'overall_accuracy': 0.9333333333333333}\n"
          ]
        }
      ],
      "source": [
        "print(get_text_classification_evaluation())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "VICfYq5bPc8h",
      "metadata": {
        "id": "VICfYq5bPc8h"
      },
      "source": [
        "# Task 3:"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Y-5svUSQPjqL",
      "metadata": {
        "id": "Y-5svUSQPjqL"
      },
      "source": [
        "## Logical Reasoning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "RUVS-B1H21Mh",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RUVS-B1H21Mh",
        "outputId": "5f5a5c7f-9f2d-44e6-a475-29fd1d5c4064"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "\"premises\": \"If it rains, the streets will be wet. It is raining.\",\n",
            "\"conclusion\": \"The streets are wet\"\n",
            "}\n",
            "-----------------------------------------------------------------------\n",
            "{\n",
            "\"premises\": \"All squares are rectangles. This shape is a square.\",\n",
            "\"conclusion\": \"This shape is a rectangle\"\n",
            "}\n",
            "-----------------------------------------------------------------------\n",
            "{\n",
            "\"premises\": \"If it is sunny, she will go for a walk. It is sunny.\",\n",
            "\"conclusion\": \"She will go for a walk\"\n",
            "}\n",
            "-----------------------------------------------------------------------\n",
            "{\n",
            "\"premises\": \"All students must pass the final exam. John is a student.\",\n",
            "\"conclusion\": \"John must pass the final exam\"\n",
            "}\n",
            "-----------------------------------------------------------------------\n",
            "{\n",
            "\"premises\": \"If the oven is turned on, the food will cook. The oven is turned on.\",\n",
            "\"conclusion\": \"The food is cooking\"\n",
            "}\n",
            "-----------------------------------------------------------------------\n",
            "{\n",
            "\"premises\": \"All prime numbers are odd. Seven is a prime number.\",\n",
            "\"conclusion\": \"Seven is odd\"\n",
            "}\n",
            "-----------------------------------------------------------------------\n",
            "{\n",
            "\"premises\": \"If he studies hard, he will pass the test. He studied hard.\",\n",
            "\"conclusion\": \"He will pass the test\"\n",
            "}\n",
            "-----------------------------------------------------------------------\n",
            "{\n",
            "\"premises\": \"All mammals have hair. Whales are mammals.\",\n",
            "\"conclusion\": \"Whales have hair\"\n",
            "}\n",
            "-----------------------------------------------------------------------\n",
            "{\n",
            "\"premises\": \"If it is cold outside, she wears a jacket. It is cold outside.\",\n",
            "\"conclusion\": \"She wears a jacket\"\n",
            "}\n",
            "-----------------------------------------------------------------------\n",
            "{\n",
            "\"premises\": \"All metals conduct electricity. Copper is a metal.\",\n",
            "\"conclusion\": \"Copper conducts electricity\"\n",
            "}\n",
            "-----------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "logical_reasoning_conclusions=[]\n",
        "for text in logical_reasoning_data:\n",
        "  response = get_completion(logical_reasoning_sys_prompt, text[0])\n",
        "  print(response)\n",
        "  print('-----------------------------------------------------------------------')\n",
        "  logical_reasoning_conclusions.append(json.loads(response)['conclusion'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Nhdx5fD-PqVW",
      "metadata": {
        "id": "Nhdx5fD-PqVW"
      },
      "source": [
        "## Reasoning Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "id": "8fx8kWxf3ft2",
      "metadata": {
        "id": "8fx8kWxf3ft2"
      },
      "outputs": [],
      "source": [
        "def display_bleu(reference, hypothesis):\n",
        "  # remove fullstops if there are any\n",
        "  if reference[-1] =='.':\n",
        "    reference = reference[:-1]\n",
        "  if hypothesis[-1] =='.':\n",
        "    hypothesis = hypothesis[:-1]\n",
        "\n",
        "  print(f'Reference: {reference}')\n",
        "  print(f'Hypothesis: {hypothesis}')\n",
        "  bleu = bleu_score.sentence_bleu([reference],hypothesis)\n",
        "  print(f'BLEU Score: {bleu}')\n",
        "  print('-----------------------------------------')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "id": "1RayybzzLslJ",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1RayybzzLslJ",
        "outputId": "c21c6f53-104f-4bcd-8464-b7daaf7d342e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reference: The streets are wet\n",
            "Hypothesis: The streets are wet\n",
            "BLEU Score: 1.0\n",
            "-----------------------------------------\n",
            "Reference: This shape is a rectangle\n",
            "Hypothesis: This shape is a rectangle\n",
            "BLEU Score: 1.0\n",
            "-----------------------------------------\n",
            "Reference: She will go for a walk\n",
            "Hypothesis: She will go for a walk\n",
            "BLEU Score: 1.0\n",
            "-----------------------------------------\n",
            "Reference: John must pass the final exam\n",
            "Hypothesis: John must pass the final exam\n",
            "BLEU Score: 1.0\n",
            "-----------------------------------------\n",
            "Reference: The food is cooking\n",
            "Hypothesis: The food is cooking\n",
            "BLEU Score: 1.0\n",
            "-----------------------------------------\n",
            "Reference: Seven is odd\n",
            "Hypothesis: Seven is odd\n",
            "BLEU Score: 1.0\n",
            "-----------------------------------------\n",
            "Reference: He will pass the test\n",
            "Hypothesis: He will pass the test\n",
            "BLEU Score: 1.0\n",
            "-----------------------------------------\n",
            "Reference: Whales have hair\n",
            "Hypothesis: Whales have hair\n",
            "BLEU Score: 1.0\n",
            "-----------------------------------------\n",
            "Reference: She wears a jacket\n",
            "Hypothesis: She wears a jacket\n",
            "BLEU Score: 1.0\n",
            "-----------------------------------------\n",
            "Reference: Copper conducts electricity\n",
            "Hypothesis: Copper conducts electricity\n",
            "BLEU Score: 1.0\n",
            "-----------------------------------------\n"
          ]
        }
      ],
      "source": [
        "for i in range(len(logical_reasoning_data)):\n",
        "  display_bleu(logical_reasoning_data[i][1],logical_reasoning_conclusions[i])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "base"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
